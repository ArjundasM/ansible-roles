---
#USER AND GROUP FOR SPARK INSTALLATION
spark_user: ubuntu
spark_group: ubuntu

#SPARK VERSION
spark_version: "2.1.0"
#HADOOP VERSION COMPATIBLE WITH SPARK VERSION 
hadoop_version: "2.6"

#SPARK URL
spark_url: https://archive.apache.org/dist/spark/spark-{{ spark_version }}/spark-{{ spark_version }}-bin-hadoop{{ hadoop_version }}.tgz 

#SPARK INSTALLATION DIRECTORY - Spark directories will present in this directory
spark_install_dir: /data

#Spark-home to set environment variable
spark_home: "{{ spark_install_dir }}/spark-{{ spark_version }}-bin-hadoop{{ hadoop_version }}"

#Fecthing hostname of master node
spark_master: "{{ hostvars[groups[master_group][0]]['ansible_nodename'] }}"

#Private ip of spark-master
spark_master_local_ip: "{{ hostvars[groups[master_group][0]]['ansible_all_ipv4_addresses'] | list | join(' ')}}"

#Spark master connection port
spark_master_connection_port: 7077

#SSH keyname
spark_keyfile: spark

#Spark key location to download into ansible server
spark_keylocation: /tmp

#Enter slaves group which mentioned in hosts file
slaves_group: slaves

#Enter master group which mentioned in hosts file
master_group: master

#Spark configuration options
spark_variables:
  SPARK_WORKER_CORES: 2     #You can allocate number of cpu's for workers
  SPARK_WORKER_WEBUI_PORT:  #Default port is 8081
  SPARK_WORKER_MEMORY: 4g   #Specify values like 4g, 400m 
  SPARK_WORKER_PORT:        #Default port is 7077
  SPARK_WORKER_INSTANCES: 4 #This number of worker instances will start in server
  SPARK_WORKER_DIR:
  SPARK_LOCAL_DIRS:
  SPARK_MASTER_OPTS:
  SPARK_WORKER_OPTS:        #to set config properties only for the worker (e.g. "-Dx=y")
  SPARK_DAEMON_MEMORY:      # to allocate to the master, worker and history server themselves (default: 1g).
  SPARK_HISTORY_OPTS:       # to set config properties only for the history server (e.g. "-Dx=y")
  SPARK_SHUFFLE_OPTS:       # to set config properties only for the external shuffle service (e.g. "-Dx=y")
  SPARK_PUBLIC_DNS:        
